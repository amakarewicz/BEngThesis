{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>algorithm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Hierarchical average</th>\n",
       "      <td>inf</td>\n",
       "      <td>1.951416</td>\n",
       "      <td>0.478705</td>\n",
       "      <td>1.288793</td>\n",
       "      <td>0.673182</td>\n",
       "      <td>0.577952</td>\n",
       "      <td>0.712849</td>\n",
       "      <td>0.712849</td>\n",
       "      <td>0.466507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hierarchical complete</th>\n",
       "      <td>inf</td>\n",
       "      <td>0.538044</td>\n",
       "      <td>0.530005</td>\n",
       "      <td>0.415432</td>\n",
       "      <td>0.625359</td>\n",
       "      <td>0.444630</td>\n",
       "      <td>0.460061</td>\n",
       "      <td>0.712849</td>\n",
       "      <td>0.498794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hierarchical single</th>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.510060</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KMeans</th>\n",
       "      <td>inf</td>\n",
       "      <td>0.471789</td>\n",
       "      <td>0.332931</td>\n",
       "      <td>0.339470</td>\n",
       "      <td>0.377618</td>\n",
       "      <td>0.401812</td>\n",
       "      <td>0.423789</td>\n",
       "      <td>0.379686</td>\n",
       "      <td>0.362581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         2         3         4         5         6         7  \\\n",
       "algorithm                                                                      \n",
       "Hierarchical average   inf  1.951416  0.478705  1.288793  0.673182  0.577952   \n",
       "Hierarchical complete  inf  0.538044  0.530005  0.415432  0.625359  0.444630   \n",
       "Hierarchical single    inf       inf       inf  0.510060       inf       inf   \n",
       "KMeans                 inf  0.471789  0.332931  0.339470  0.377618  0.401812   \n",
       "\n",
       "                              8         9        10  \n",
       "algorithm                                            \n",
       "Hierarchical average   0.712849  0.712849  0.466507  \n",
       "Hierarchical complete  0.460061  0.712849  0.498794  \n",
       "Hierarchical single         inf       inf       inf  \n",
       "KMeans                 0.423789  0.379686  0.362581  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import plot\n",
    "from dtaidistance import dtw_ndim\n",
    "\n",
    "\n",
    "data = pd.read_csv('metrics_results.csv')\n",
    "\n",
    "for m in data.columns.drop(['algorithm', 'n_clusters']):\n",
    "    df_test = data[['algorithm','n_clusters', m]]\n",
    "\n",
    "    # transposing\n",
    "    df_test_transposed = df_test.pivot_table(index='algorithm', columns=['n_clusters'], values=m).reset_index()\n",
    "    df_test_final = df_test_transposed.rename_axis('').rename_axis(\"\", axis=\"columns\").set_index('algorithm')\n",
    "\n",
    "    #df_test_final.T.plot(figsize=(20,10), title=ind)\n",
    "\n",
    "df_test_final.head()\n",
    "# plot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuning for optimal k\n",
    "# k_max = 10\n",
    "# silhouette = []\n",
    "# chscore = []\n",
    "# dunnindex = []\n",
    "# for k in range(2, k_max+1):\n",
    "#     kmeans = kmeans_clustering(data, k)\n",
    "#     silhouette.append(silhouette_score(dtw_matrix, kmeans.labels_))\n",
    "#     chscore.append(symbolicDA.index_G1d(dtw_matrix, kmeans.labels_)[0])\n",
    "#     dunnindex.append(clValid.dunn(dtw_matrix, kmeans.labels_)[0])\n",
    "# for k in range(2, k_max+1):\n",
    "#     agg_average = agglomerative_clustering(data, k, linkage='average')\n",
    "#     silhouette.append(silhouette_score(dtw_matrix, agg_average.labels_))\n",
    "#     chscore.append(symbolicDA.index_G1d(dtw_matrix, agg_average.labels_)[0])\n",
    "#     dunnindex.append(clValid.dunn(dtw_matrix, agg_average.labels_)[0])\n",
    "# for k in range(2, k_max+1):\n",
    "#     agg_complete = agglomerative_clustering(data, k, linkage='complete')\n",
    "#     silhouette.append(silhouette_score(dtw_matrix, agg_complete.labels_))\n",
    "#     chscore.append(symbolicDA.index_G1d(dtw_matrix, agg_complete.labels_)[0])\n",
    "#     dunnindex.append(clValid.dunn(dtw_matrix, agg_complete.labels_)[0])\n",
    "# for k in range(2, k_max+1):\n",
    "#     agg_single = agglomerative_clustering(data, k, linkage='single')\n",
    "#     silhouette.append(silhouette_score(dtw_matrix, agg_single.labels_))\n",
    "#     chscore.append(symbolicDA.index_G1d(dtw_matrix, agg_single.labels_)[0])\n",
    "#     dunnindex.append(clValid.dunn(dtw_matrix, agg_single.labels_)[0])\n",
    "# metrics = pd.DataFrame({'silhouette' : silhouette, 'chscore' : chscore, 'dunnindex' : dunnindex})\n",
    "# metrics['algorithm'] = pd.Series(['KMeans']*9 + ['Hierarchical average']*9 + ['Hierarchical complete']*9 + ['Hierarchical single']*9)\n",
    "# metrics['n_clusters'] = pd.Series([x for x in range(2,11)]*4)\n",
    "# metrics = metrics[['algorithm', 'n_clusters', 'silhouette', 'chscore', 'dunnindex']]\n",
    "# metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'temp-plot.html'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [go.Scatter(x=df_test_final.columns,\n",
    "                   y=df_test_final.loc[countrycode],\n",
    "                   name=countrycode) for countrycode in df_test_final.index]\n",
    "\n",
    "layout = go.Layout(\n",
    "    title= ind.upper(),\n",
    "    yaxis=dict(title='Value'),\n",
    "    xaxis=dict(title='Years')\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "plot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7116/983628334.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'metrics_results.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('metrics_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly\n",
    "import plotly.graph_objs as go \n",
    "\n",
    "data = pd.read_csv('metrics_results.csv')\n",
    "# Initialize figure\n",
    "def plot_series(data: pd.DataFrame) -> None:\n",
    "    \"\"\"AI is creating summary for plot_series\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): [description]\n",
    "    \"\"\"\n",
    "    fig = go.Figure()\n",
    "    buttons = list()\n",
    "    for i in range(data.shape[1]-2):\n",
    "        m = data.columns[i+2,]\n",
    "        df_test = data[['algorithm','n_clusters', m]]\n",
    "\n",
    "        # transposing\n",
    "        df_test_transposed = df_test.pivot_table(index='algorithm', columns=['n_clusters'], values=m).reset_index()\n",
    "        df_test_final = df_test_transposed.rename_axis('').rename_axis(\"\", axis=\"columns\").set_index('algorithm')\n",
    "\n",
    "        # Add Traces\n",
    "        for alg in df_test_final.index:\n",
    "            if i==0:\n",
    "                fig.add_trace(go.Scatter(x=df_test_final.columns, y=df_test_final.loc[alg],\n",
    "                        name=alg, visible=True))            \n",
    "            else:\n",
    "                fig.add_trace(go.Scatter(x=df_test_final.columns, y=df_test_final.loc[alg],\n",
    "                        name=alg, visible=False))\n",
    "        n_of_countries = df_test_final.shape[0]\n",
    "        visible = [False]*n_of_countries*i + [True]*n_of_countries + [False]*n_of_countries*(n_of_countries-i-1)\n",
    "        buttons.append(dict(label = m,\n",
    "                    method = 'update',\n",
    "                    args = [{'visible': visible},\n",
    "                            {'title': m}]))    \n",
    "    fig.update_layout(dict(updatemenus=[\n",
    "                        # dict(\n",
    "                        #     type = \"buttons\",\n",
    "                        #     direction = \"left\",\n",
    "                        #     buttons=list([\n",
    "                        #         dict(\n",
    "                        #             args=[\"visible\", \"legendonly\"],\n",
    "                        #             label=\"Deselect All\",\n",
    "                        #             method=\"restyle\"\n",
    "                        #         ),\n",
    "                        #         dict(\n",
    "                        #             args=[\"visible\", True],\n",
    "                        #             label=\"Select All\",\n",
    "                        #             method=\"restyle\"\n",
    "                        #         )\n",
    "                        #     ]),\n",
    "                        #     pad={\"r\": 10, \"t\": 10},\n",
    "                        #     showactive=True,\n",
    "                        #     x=1,\n",
    "                        #     xanchor=\"right\",\n",
    "                        #     y=1.1,\n",
    "                        #     yanchor=\"top\"\n",
    "                        # ),\n",
    "                        dict(type='dropdown', buttons=buttons, xanchor='right', x=1, y=1.15, active=0)#, showactive=True)                    ]\n",
    "    ]))\n",
    "    # updatemenus = list([\n",
    "    #     dict(active=-1, type='dropdown',\n",
    "    #         buttons=buttons, xanchor='right', x=1, y=1.15\n",
    "            \n",
    "    #     )\n",
    "    # ])\n",
    "\n",
    "    \n",
    "    fig.update_layout(title='Series')#, title_pad_l=40, title_xanchor='left')\n",
    "    plot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_series(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import numpy as np\n",
    "\n",
    "def plot_dbscan(countries: pd.DataFrame, labels: np.array) -> None:\n",
    "    \"\"\"\n",
    "    Plot cartogram presenting clustering results for given countries.\n",
    "\n",
    "    Args:\n",
    "        countries (pd.DataFrame): Pandas Dataframe containing at least one column, named 'countrycode',\n",
    "        with ISO-3166 alpha-3 codes of countries\n",
    "        labels (np.array): cluster assignment generated by clustering model for given countries\n",
    "    \"\"\"\n",
    "    labels = labels.astype(str)\n",
    "    countries[\"cluster\"] = pd.Series(labels)\n",
    "    fig = px.choropleth(countries, locations='countrycode', color=\"cluster\",\n",
    "                        projection='conic conformal', color_discrete_sequence=px.colors.qualitative.Pastel)\n",
    "    fig.update_geos(lataxis_range=[35, 75], lonaxis_range=[-15, 45])  # customized to show Europe only\n",
    "    fig.update_layout(showlegend=False, margin=dict(l=20, r=20, t=20, b=20), paper_bgcolor='rgba(0,0,0,0)')\n",
    "    return fig.to_html(full_html=False, default_height=400, default_width=400)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dbscan_clustering(data: pd.DataFrame, eps: float, min_samples: int) -> DBSCAN:\n",
    "    \"\"\"\n",
    "    Perform DBSCAN clustering.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): preprocessed dataframe with economic indexes\n",
    "        eps (float): maximum distance between two points for them to be considered as neighbouring\n",
    "        min_samples (int): number of samples in a neighborhood for a point to be considered as a core point\n",
    "\n",
    "    Returns:\n",
    "        DBSCAN: fitted clustering model\n",
    "    \"\"\"\n",
    "    # transform input data into adequate structure - 3D numpy array\n",
    "    data_t = data.melt(id_vars=['countrycode', 'country', 'year'])\n",
    "    data_t = data_t.groupby(['countrycode', 'country', 'year', 'variable'])['value'].aggregate('mean').unstack(\n",
    "        'year')\n",
    "    data_t = data_t.reset_index().drop('variable', axis=1).groupby(['countrycode', 'country']).agg(list)\n",
    "    n_countries = data_t.shape[0]  # number of points (countries)\n",
    "    time_range = data_t.shape[1]  # time range\n",
    "    n_vars = data.shape[1] - 3  # number of economic indexes\n",
    "    # filling the array\n",
    "    data_t_arr = np.empty(shape=(n_countries, time_range, n_vars))\n",
    "    for i in range(n_countries):\n",
    "        for j in range(time_range):\n",
    "            data_t_arr[i][j] = np.array(data_t.iloc[i, j])\n",
    "    # calculating distances between points (countries)\n",
    "    dtw_matrix = dtw_ndim.distance_matrix_fast(data_t_arr, n_vars)\n",
    "    # creating and fitting the model\n",
    "    model = DBSCAN(eps=eps, min_samples=min_samples, metric='precomputed')\n",
    "    model.fit(dtw_matrix)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'temp-plot.html'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import plotly\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\n",
    "\n",
    "# def plot_dbscan(df, countries, labels):\n",
    "data = pd.read_csv('data/data.csv')\n",
    "\n",
    "# transform input data into adequate structure - 3D numpy array\n",
    "data_t = data.melt(id_vars=['countrycode', 'country', 'year'])\n",
    "data_t = data_t.groupby(['countrycode', 'country', 'year', 'variable'])['value'].aggregate('mean').unstack(\n",
    "    'year')\n",
    "data_t = data_t.reset_index().drop('variable', axis=1).groupby(['countrycode', 'country']).agg(list)\n",
    "n_countries = data_t.shape[0]  # number of points (countries)\n",
    "time_range = data_t.shape[1]  # time range\n",
    "n_vars = data.shape[1] - 3  # number of economic indexes\n",
    "# filling the array\n",
    "data_t_arr = np.empty(shape=(n_countries, time_range, n_vars))\n",
    "for i in range(n_countries):\n",
    "    for j in range(time_range):\n",
    "        data_t_arr[i][j] = np.array(data_t.iloc[i, j])\n",
    "# calculating distances between points (countries)\n",
    "dtw_matrix = dtw_ndim.distance_matrix_fast(data_t_arr, n_vars)\n",
    "\n",
    "# labels = labels.astype(str)\n",
    "# countries[\"cluster\"] = pd.Series(labels)\n",
    "# data = [dict(type='choropleth',\n",
    "#             locations = countries['countrycode'].astype(str),\n",
    "#             color=countries['cluster'].astype(int),\n",
    "#             projection='conic conformal', color_discrete_sequence=px.colors.qualitative.Pastel)]\n",
    "countries = data[['countrycode','country']].drop_duplicates().reset_index(drop=True)\n",
    "# let's create some additional, random data \n",
    "\n",
    "##### WYKRES ######\n",
    "eps_grid = [3, 3.1, 3.2, 3.3, 3.4, 3.5]\n",
    "min_samples_grid = [2,3,4,5,6]\n",
    "plot_data = []\n",
    "for eps in eps_grid:\n",
    "    for min_samples in min_samples_grid:\n",
    "        model = DBSCAN(eps=eps, min_samples=min_samples, metric='precomputed')\n",
    "        model.fit(dtw_matrix)\n",
    "        plot_data.append(dict(type='choropleth',\n",
    "                locations = countries['countrycode'].astype(str),\n",
    "                z=model.labels_))\n",
    "# (3,2), (3,3) ... (3.1, 2), (3.1, 3) \n",
    "\n",
    "# let's create the steps for the slider\n",
    "# eps\n",
    "steps1 = []\n",
    "for i in range(len(plot_data)):\n",
    "    step = dict(method='restyle',\n",
    "                args=['visible', [False] * len(plot_data)],\n",
    "                label='Eps {}'.format(3+ i/10))\n",
    "    step['args'][1][i] = True\n",
    "    steps1.append(step)\n",
    "# min_samples\n",
    "steps2 = []\n",
    "for i in range(len(plot_data)):\n",
    "    step = dict(method='restyle',\n",
    "                args=['visible', [False] * len(plot_data)],\n",
    "                label='Eps2 {}'.format(3+ i/10))\n",
    "    step['args'][1][i] = True\n",
    "    steps2.append(step)\n",
    "\n",
    "sliders = [dict(active=0,\n",
    "                y=-1,\n",
    "                pad={\"t\": 1},\n",
    "                steps=steps1),\n",
    "                dict(active=0,\n",
    "                pad={\"t\": 1},\n",
    "                steps=steps2)]    \n",
    "layout = dict(geo=dict(projection={'type': 'conic conformal'}, lataxis={'range':[35,75]}, \n",
    " lonaxis={'range' : [-15, 45]}),\n",
    "            sliders=sliders)\n",
    "\n",
    "fig = dict(data=plot_data, \n",
    "        layout=layout)\n",
    "\n",
    "plot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0d1bfbd48ac9d0d45d3e1ecabc58d25c00d90cf1449842edf85d52c9d4642455"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('thesis': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
