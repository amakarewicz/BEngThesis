{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>algorithm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Hierarchical average</th>\n",
       "      <td>1.951416</td>\n",
       "      <td>0.478705</td>\n",
       "      <td>1.288793</td>\n",
       "      <td>0.673182</td>\n",
       "      <td>0.577952</td>\n",
       "      <td>0.712849</td>\n",
       "      <td>0.712849</td>\n",
       "      <td>0.466507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hierarchical complete</th>\n",
       "      <td>0.538044</td>\n",
       "      <td>0.530005</td>\n",
       "      <td>0.415432</td>\n",
       "      <td>0.625359</td>\n",
       "      <td>0.444630</td>\n",
       "      <td>0.460061</td>\n",
       "      <td>0.712849</td>\n",
       "      <td>0.498794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hierarchical single</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.510060</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KMeans</th>\n",
       "      <td>0.471789</td>\n",
       "      <td>0.332931</td>\n",
       "      <td>0.339470</td>\n",
       "      <td>0.377618</td>\n",
       "      <td>0.401812</td>\n",
       "      <td>0.423789</td>\n",
       "      <td>0.379686</td>\n",
       "      <td>0.362581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              3         4         5         6         7  \\\n",
       "algorithm                                                                 \n",
       "Hierarchical average   1.951416  0.478705  1.288793  0.673182  0.577952   \n",
       "Hierarchical complete  0.538044  0.530005  0.415432  0.625359  0.444630   \n",
       "Hierarchical single         NaN       NaN  0.510060       NaN       NaN   \n",
       "KMeans                 0.471789  0.332931  0.339470  0.377618  0.401812   \n",
       "\n",
       "                              8         9        10  \n",
       "algorithm                                            \n",
       "Hierarchical average   0.712849  0.712849  0.466507  \n",
       "Hierarchical complete  0.460061  0.712849  0.498794  \n",
       "Hierarchical single         NaN       NaN       NaN  \n",
       "KMeans                 0.423789  0.379686  0.362581  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import plot\n",
    "from dtaidistance import dtw_ndim\n",
    "\n",
    "\n",
    "data = pd.read_csv('data/metrics_results.csv')\n",
    "\n",
    "for m in data.columns.drop(['algorithm', 'n_clusters']):\n",
    "    df_test = data[['algorithm','n_clusters', m]]\n",
    "\n",
    "    # transposing\n",
    "    df_test_transposed = df_test.pivot_table(index='algorithm', columns=['n_clusters'], values=m).reset_index()\n",
    "    df_test_final = df_test_transposed.rename_axis('').rename_axis(\"\", axis=\"columns\").set_index('algorithm')\n",
    "\n",
    "    #df_test_final.T.plot(figsize=(20,10), title=ind)\n",
    "\n",
    "df_test_final.head()\n",
    "# plot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuning for optimal k\n",
    "# k_max = 10\n",
    "# silhouette = []\n",
    "# chscore = []\n",
    "# dunnindex = []\n",
    "# for k in range(2, k_max+1):\n",
    "#     kmeans = kmeans_clustering(data, k)\n",
    "#     silhouette.append(silhouette_score(dtw_matrix, kmeans.labels_))\n",
    "#     chscore.append(symbolicDA.index_G1d(dtw_matrix, kmeans.labels_)[0])\n",
    "#     dunnindex.append(clValid.dunn(dtw_matrix, kmeans.labels_)[0])\n",
    "# for k in range(2, k_max+1):\n",
    "#     agg_average = agglomerative_clustering(data, k, linkage='average')\n",
    "#     silhouette.append(silhouette_score(dtw_matrix, agg_average.labels_))\n",
    "#     chscore.append(symbolicDA.index_G1d(dtw_matrix, agg_average.labels_)[0])\n",
    "#     dunnindex.append(clValid.dunn(dtw_matrix, agg_average.labels_)[0])\n",
    "# for k in range(2, k_max+1):\n",
    "#     agg_complete = agglomerative_clustering(data, k, linkage='complete')\n",
    "#     silhouette.append(silhouette_score(dtw_matrix, agg_complete.labels_))\n",
    "#     chscore.append(symbolicDA.index_G1d(dtw_matrix, agg_complete.labels_)[0])\n",
    "#     dunnindex.append(clValid.dunn(dtw_matrix, agg_complete.labels_)[0])\n",
    "# for k in range(2, k_max+1):\n",
    "#     agg_single = agglomerative_clustering(data, k, linkage='single')\n",
    "#     silhouette.append(silhouette_score(dtw_matrix, agg_single.labels_))\n",
    "#     chscore.append(symbolicDA.index_G1d(dtw_matrix, agg_single.labels_)[0])\n",
    "#     dunnindex.append(clValid.dunn(dtw_matrix, agg_single.labels_)[0])\n",
    "# metrics = pd.DataFrame({'silhouette' : silhouette, 'chscore' : chscore, 'dunnindex' : dunnindex})\n",
    "# metrics['algorithm'] = pd.Series(['KMeans']*9 + ['Hierarchical average']*9 + ['Hierarchical complete']*9 + ['Hierarchical single']*9)\n",
    "# metrics['n_clusters'] = pd.Series([x for x in range(2,11)]*4)\n",
    "# metrics = metrics[['algorithm', 'n_clusters', 'silhouette', 'chscore', 'dunnindex']]\n",
    "# metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = [go.Scatter(x=df_test_final.columns,\n",
    "#                    y=df_test_final.loc[countrycode],\n",
    "#                    name=countrycode) for countrycode in df_test_final.index]\n",
    "\n",
    "# layout = go.Layout(\n",
    "#     title= ind.upper(),\n",
    "#     yaxis=dict(title='Value'),\n",
    "#     xaxis=dict(title='Years')\n",
    "# )\n",
    "\n",
    "# fig = go.Figure(data=data, layout=layout)\n",
    "# plot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly\n",
    "import plotly.graph_objs as go \n",
    "\n",
    "data = pd.read_csv('data/metrics_results.csv')\n",
    "# Initialize figure\n",
    "def plot_series(data: pd.DataFrame) -> None:\n",
    "    \"\"\"AI is creating summary for plot_series\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): [description]\n",
    "    \"\"\"\n",
    "    fig = go.Figure()\n",
    "    buttons = list()\n",
    "    for i in range(data.shape[1]-2):\n",
    "        m = data.columns[i+2,]\n",
    "        df_test = data[['algorithm','n_clusters', m]]\n",
    "\n",
    "        # transposing\n",
    "        df_test_transposed = df_test.pivot_table(index='algorithm', columns=['n_clusters'], values=m).reset_index()\n",
    "        df_test_final = df_test_transposed.rename_axis('').rename_axis(\"\", axis=\"columns\").set_index('algorithm')\n",
    "\n",
    "        # Add Traces\n",
    "        for alg in df_test_final.index:\n",
    "            if i==0:\n",
    "                fig.add_trace(go.Scatter(x=df_test_final.columns, y=df_test_final.loc[alg],\n",
    "                        name=alg, visible=True))            \n",
    "            else:\n",
    "                fig.add_trace(go.Scatter(x=df_test_final.columns, y=df_test_final.loc[alg],\n",
    "                        name=alg, visible=False))\n",
    "        n_of_countries = df_test_final.shape[0]\n",
    "        visible = [False]*n_of_countries*i + [True]*n_of_countries + [False]*n_of_countries*(n_of_countries-i-1)\n",
    "        buttons.append(dict(label = m,\n",
    "                    method = 'update',\n",
    "                    args = [{'visible': visible},\n",
    "                            {'title': m}]))    \n",
    "    fig.update_layout(dict(updatemenus=[\n",
    "                        # dict(\n",
    "                        #     type = \"buttons\",\n",
    "                        #     direction = \"left\",\n",
    "                        #     buttons=list([\n",
    "                        #         dict(\n",
    "                        #             args=[\"visible\", \"legendonly\"],\n",
    "                        #             label=\"Deselect All\",\n",
    "                        #             method=\"restyle\"\n",
    "                        #         ),\n",
    "                        #         dict(\n",
    "                        #             args=[\"visible\", True],\n",
    "                        #             label=\"Select All\",\n",
    "                        #             method=\"restyle\"\n",
    "                        #         )\n",
    "                        #     ]),\n",
    "                        #     pad={\"r\": 10, \"t\": 10},\n",
    "                        #     showactive=True,\n",
    "                        #     x=1,\n",
    "                        #     xanchor=\"right\",\n",
    "                        #     y=1.1,\n",
    "                        #     yanchor=\"top\"\n",
    "                        # ),\n",
    "                        dict(type='dropdown', buttons=buttons, xanchor='right', x=1, y=1.15, active=0)#, showactive=True)                    ]\n",
    "    ]))\n",
    "    # updatemenus = list([\n",
    "    #     dict(active=-1, type='dropdown',\n",
    "    #         buttons=buttons, xanchor='right', x=1, y=1.15\n",
    "            \n",
    "    #     )\n",
    "    # ])\n",
    "\n",
    "    \n",
    "    fig.update_layout(title='Series')#, title_pad_l=40, title_xanchor='left')\n",
    "    plot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_series(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import numpy as np\n",
    "\n",
    "def plot_dbscan(countries: pd.DataFrame, labels: np.array) -> None:\n",
    "    \"\"\"\n",
    "    Plot cartogram presenting clustering results for given countries.\n",
    "\n",
    "    Args:\n",
    "        countries (pd.DataFrame): Pandas Dataframe containing at least one column, named 'countrycode',\n",
    "        with ISO-3166 alpha-3 codes of countries\n",
    "        labels (np.array): cluster assignment generated by clustering model for given countries\n",
    "    \"\"\"\n",
    "    labels = labels.astype(str)\n",
    "    countries[\"cluster\"] = pd.Series(labels)\n",
    "    fig = px.choropleth(countries, locations='countrycode', color=\"cluster\",\n",
    "                        projection='conic conformal', color_discrete_sequence=px.colors.qualitative.Pastel)\n",
    "    fig.update_geos(lataxis_range=[35, 75], lonaxis_range=[-15, 45])  # customized to show Europe only\n",
    "    fig.update_layout(showlegend=False, margin=dict(l=20, r=20, t=20, b=20), paper_bgcolor='rgba(0,0,0,0)')\n",
    "    return fig.to_html(full_html=False, default_height=400, default_width=400)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "def dbscan_clustering(data: pd.DataFrame, eps: float, min_samples: int) -> DBSCAN:\n",
    "    \"\"\"\n",
    "    Perform DBSCAN clustering.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): preprocessed dataframe with economic indexes\n",
    "        eps (float): maximum distance between two points for them to be considered as neighbouring\n",
    "        min_samples (int): number of samples in a neighborhood for a point to be considered as a core point\n",
    "\n",
    "    Returns:\n",
    "        DBSCAN: fitted clustering model\n",
    "    \"\"\"\n",
    "    # transform input data into adequate structure - 3D numpy array\n",
    "    data_t = data.melt(id_vars=['countrycode', 'country', 'year'])\n",
    "    data_t = data_t.groupby(['countrycode', 'country', 'year', 'variable'])['value'].aggregate('mean').unstack(\n",
    "        'year')\n",
    "    data_t = data_t.reset_index().drop('variable', axis=1).groupby(['countrycode', 'country']).agg(list)\n",
    "    n_countries = data_t.shape[0]  # number of points (countries)\n",
    "    time_range = data_t.shape[1]  # time range\n",
    "    n_vars = data.shape[1] - 3  # number of economic indexes\n",
    "    # filling the array\n",
    "    data_t_arr = np.empty(shape=(n_countries, time_range, n_vars))\n",
    "    for i in range(n_countries):\n",
    "        for j in range(time_range):\n",
    "            data_t_arr[i][j] = np.array(data_t.iloc[i, j])\n",
    "    # calculating distances between points (countries)\n",
    "    dtw_matrix = dtw_ndim.distance_matrix_fast(data_t_arr, n_vars)\n",
    "    # creating and fitting the model\n",
    "    model = DBSCAN(eps=eps, min_samples=min_samples, metric='precomputed')\n",
    "    model.fit(dtw_matrix)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\n",
    "\n",
    "# def plot_dbscan(df, countries, labels):\n",
    "data = pd.read_csv('data/data.csv')\n",
    "\n",
    "# transform input data into adequate structure - 3D numpy array\n",
    "data_t = data.melt(id_vars=['countrycode', 'country', 'year'])\n",
    "data_t = data_t.groupby(['countrycode', 'country', 'year', 'variable'])['value'].aggregate('mean').unstack(\n",
    "    'year')\n",
    "data_t = data_t.reset_index().drop('variable', axis=1).groupby(['countrycode', 'country']).agg(list)\n",
    "n_countries = data_t.shape[0]  # number of points (countries)\n",
    "time_range = data_t.shape[1]  # time range\n",
    "n_vars = data.shape[1] - 3  # number of economic indexes\n",
    "# filling the array\n",
    "data_t_arr = np.empty(shape=(n_countries, time_range, n_vars))\n",
    "for i in range(n_countries):\n",
    "    for j in range(time_range):\n",
    "        data_t_arr[i][j] = np.array(data_t.iloc[i, j])\n",
    "# calculating distances between points (countries)\n",
    "dtw_matrix = dtw_ndim.distance_matrix_fast(data_t_arr, n_vars)\n",
    "\n",
    "# labels = labels.astype(str)\n",
    "# countries[\"cluster\"] = pd.Series(labels)\n",
    "# data = [dict(type='choropleth',\n",
    "#             locations = countries['countrycode'].astype(str),\n",
    "#             color=countries['cluster'].astype(int),\n",
    "#             projection='conic conformal', color_discrete_sequence=px.colors.qualitative.Pastel)]\n",
    "countries = data[['countrycode','country']].drop_duplicates().reset_index(drop=True)\n",
    "# let's create some additional, random data \n",
    "\n",
    "##### WYKRES ######\n",
    "eps_grid = [3, 3.1, 3.2, 3.3, 3.4, 3.5]\n",
    "min_samples_grid = [2,3,4,5,6]\n",
    "plot_data = []\n",
    "for eps in eps_grid:\n",
    "    for min_samples in min_samples_grid:\n",
    "        model = DBSCAN(eps=eps, min_samples=min_samples, metric='precomputed')\n",
    "        model.fit(dtw_matrix)\n",
    "        plot_data.append(dict(type='choropleth',\n",
    "                locations = countries['countrycode'].astype(str),\n",
    "                z=model.labels_))\n",
    "# (3,2), (3,3) ... (3.1, 2), (3.1, 3) \n",
    "\n",
    "# let's create the steps for the slider\n",
    "# eps\n",
    "steps = []\n",
    "i=0\n",
    "for eps in eps_grid:\n",
    "    for min_samples in min_samples_grid:\n",
    "        step = dict(method='restyle',\n",
    "                    args=['visible', [False] * len(plot_data)],\n",
    "                    label='{} / {}'.format(eps, min_samples))\n",
    "        step['args'][1][i] = True\n",
    "        steps.append(step)\n",
    "        i+=1\n",
    "# min_samples\n",
    "# steps2 = []\n",
    "# for i in range(len(plot_data)):\n",
    "#     step = dict(method='restyle',\n",
    "#                 args=['visible', [False] * len(plot_data)],\n",
    "#                 label='Eps2 {}'.format(3+ i/10))\n",
    "#     step['args'][1][i] = True\n",
    "#     steps2.append(step)\n",
    "\n",
    "sliders = [dict(active=0,\n",
    "                pad={\"t\": 1},\n",
    "                steps=steps,\n",
    "                currentvalue={'prefix':'Eps - ',\n",
    "                'suffix':' - min samples'})]\n",
    "                # dict(active=0,\n",
    "                # pad={\"t\": 1},\n",
    "                # steps=steps2)]    \n",
    "layout = dict(geo=dict(projection={'type': 'conic conformal'}, lataxis={'range':[35,75]}, \n",
    " lonaxis={'range' : [-15, 45]}),\n",
    "            sliders=sliders)\n",
    "\n",
    "fig = dict(data=plot_data, \n",
    "        layout=layout)\n",
    "#fig.update_layout(showlegend=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_dbscan(df, countries, labels):\n",
    "data = pd.read_csv('data/data.csv')\n",
    "\n",
    "year_grid = [x for x in range(1999,2020,1)]\n",
    "plot_data = []\n",
    "for year in year_grid:\n",
    "        model = DBSCAN(eps=eps, min_samples=min_samples, metric='precomputed')\n",
    "        model.fit(dtw_matrix)\n",
    "        plot_data.append(dict(type='choropleth',\n",
    "                locations = countries['countrycode'].astype(str),\n",
    "                z=model.labels_))\n",
    "# transform input data into adequate structure - 3D numpy array\n",
    "data_t = data.melt(id_vars=['countrycode', 'country', 'year'])\n",
    "data_t = data_t.groupby(['countrycode', 'country', 'year', 'variable'])['value'].aggregate('mean').unstack(\n",
    "    'year')\n",
    "data_t = data_t.reset_index().drop('variable', axis=1).groupby(['countrycode', 'country']).agg(list)\n",
    "n_countries = data_t.shape[0]  # number of points (countries)\n",
    "time_range = data_t.shape[1]  # time range\n",
    "n_vars = data.shape[1] - 3  # number of economic indexes\n",
    "# filling the array\n",
    "data_t_arr = np.empty(shape=(n_countries, time_range, n_vars))\n",
    "for i in range(n_countries):\n",
    "    for j in range(time_range):\n",
    "        data_t_arr[i][j] = np.array(data_t.iloc[i, j])\n",
    "# calculating distances between points (countries)\n",
    "dtw_matrix = dtw_ndim.distance_matrix_fast(data_t_arr, n_vars)\n",
    "\n",
    "# labels = labels.astype(str)\n",
    "# countries[\"cluster\"] = pd.Series(labels)\n",
    "# data = [dict(type='choropleth',\n",
    "#             locations = countries['countrycode'].astype(str),\n",
    "#             color=countries['cluster'].astype(int),\n",
    "#             projection='conic conformal', color_discrete_sequence=px.colors.qualitative.Pastel)]\n",
    "countries = data[['countrycode','country']].drop_duplicates().reset_index(drop=True)\n",
    "# let's create some additional, random data \n",
    "\n",
    "##### WYKRES ######\n",
    "eps_grid = [3, 3.1, 3.2, 3.3, 3.4, 3.5]\n",
    "min_samples_grid = [2,3,4,5,6]\n",
    "plot_data = []\n",
    "for eps in eps_grid:\n",
    "    for min_samples in min_samples_grid:\n",
    "        model = DBSCAN(eps=eps, min_samples=min_samples, metric='precomputed')\n",
    "        model.fit(dtw_matrix)\n",
    "        plot_data.append(dict(type='choropleth',\n",
    "                locations = countries['countrycode'].astype(str),\n",
    "                z=model.labels_))\n",
    "# (3,2), (3,3) ... (3.1, 2), (3.1, 3) \n",
    "\n",
    "# let's create the steps for the slider\n",
    "# eps\n",
    "steps = []\n",
    "i=0\n",
    "for eps in eps_grid:\n",
    "    for min_samples in min_samples_grid:\n",
    "        step = dict(method='restyle',\n",
    "                    args=['visible', [False] * len(plot_data)],\n",
    "                    label='{} / {}'.format(eps, min_samples))\n",
    "        step['args'][1][i] = True\n",
    "        steps.append(step)\n",
    "        i+=1\n",
    "# min_samples\n",
    "# steps2 = []\n",
    "# for i in range(len(plot_data)):\n",
    "#     step = dict(method='restyle',\n",
    "#                 args=['visible', [False] * len(plot_data)],\n",
    "#                 label='Eps2 {}'.format(3+ i/10))\n",
    "#     step['args'][1][i] = True\n",
    "#     steps2.append(step)\n",
    "\n",
    "sliders = [dict(active=0,\n",
    "                pad={\"t\": 1},\n",
    "                steps=steps,\n",
    "                currentvalue={'prefix':'Eps - ',\n",
    "                'suffix':' - min samples'})]\n",
    "                # dict(active=0,\n",
    "                # pad={\"t\": 1},\n",
    "                # steps=steps2)]    \n",
    "layout = dict(geo=dict(projection={'type': 'conic conformal'}, lataxis={'range':[35,75]}, \n",
    " lonaxis={'range' : [-15, 45]}),\n",
    "            sliders=sliders)\n",
    "\n",
    "fig = dict(data=plot_data, \n",
    "        layout=layout)\n",
    "#fig.update_layout(showlegend=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_clustering(data: pd.DataFrame, n_clusters: int) -> TimeSeriesKMeans:\n",
    "    \"\"\"\n",
    "    Perform KMeans clustering.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): preprocessed dataframe with economic indexes\n",
    "        n_clusters (int): number of clusters to be formed\n",
    "\n",
    "    Returns:\n",
    "        TimeSeriesKMeans: fitted clustering model\n",
    "    \"\"\"\n",
    "    # transform input data into adequate structure - 3D numpy array\n",
    "    data_agg = data.drop('year', axis=1).groupby(['countrycode', 'country']).agg(list)\n",
    "    n_countries = data_agg.shape[0] # number of points (countries)\n",
    "    time_range =  len(data['year'].drop_duplicates()) # time range\n",
    "    n_vars = data.shape[1] - 3 # number of economic indexes\n",
    "    # filling the array\n",
    "    data_agg_arr = np.empty(shape=(n_countries, n_vars, time_range))\n",
    "    for i in range(data_agg.shape[0]):\n",
    "        for j in range(data_agg.shape[1]):\n",
    "            data_agg_arr[i][j] = np.array(data_agg.iloc[i,j])\n",
    "    # creating and fitting a model\n",
    "    model = TimeSeriesKMeans(n_clusters=n_clusters, metric='dtw', random_state=123)\n",
    "    model.fit(data_agg_arr)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\agama\\Documents\\BEngThesis\\django\\bengthesis\\lib\\site-packages\\tslearn\\bases\\bases.py:15: UserWarning: h5py not installed, hdf5 features will not be supported.\n",
      "Install h5py to use hdf5 features: http://docs.h5py.org/\n",
      "  warn(h5py_msg)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from tslearn.preprocessing import TimeSeriesScalerMeanVariance\n",
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "from dtaidistance import dtw_ndim\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "def agglomerative_clustering(data: pd.DataFrame, n_clusters: int, linkage: str) -> AgglomerativeClustering:\n",
    "    \"\"\"\n",
    "    Perform hierarchical clustering.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): preprocessed dataframe with economic indexes\n",
    "        n_clusters (int): number of clusters to be formed\n",
    "        linkage (str): type of linkage criterion; 'average', 'complete' or 'single'\n",
    "\n",
    "    Returns:\n",
    "        AgglomerativeClustering: fitted clustering model\n",
    "    \"\"\"\n",
    "    # transform input data into adequate structure - 3D numpy array\n",
    "    data_t = data.melt(id_vars=['countrycode','country','year'])\n",
    "    data_t = data_t.groupby(['countrycode','country','year','variable'])['value'].aggregate('mean').unstack('year')\n",
    "    data_t = data_t.reset_index().drop('variable', axis=1).groupby(['countrycode', 'country']).agg(list)\n",
    "    n_countries = data_t.shape[0] # number of points (countries)\n",
    "    time_range =  data_t.shape[1] # time range\n",
    "    n_vars = data.shape[1] - 3 # number of economic indexes\n",
    "    # filling the array\n",
    "    data_t_arr = np.empty(shape=(n_countries, time_range, n_vars))\n",
    "    for i in range(n_countries):\n",
    "        for j in range(time_range):\n",
    "            data_t_arr[i][j] = np.array(data_t.iloc[i,j])\n",
    "    # calculating distances between points (countries)\n",
    "    dtw_matrix = dtw_ndim.distance_matrix_fast(data_t_arr, n_vars)\n",
    "    # creating and fitting the model\n",
    "    model = AgglomerativeClustering(\n",
    "        n_clusters=n_clusters, affinity='precomputed', linkage=linkage, compute_distances=True)\n",
    "    model.fit(dtw_matrix)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1990 1991 1992 1993 1994 1995 1996 1997 1998 1999]\n",
      "[1991 1992 1993 1994 1995 1996 1997 1998 1999 2000]\n",
      "[1992 1993 1994 1995 1996 1997 1998 1999 2000 2001]\n",
      "[1993 1994 1995 1996 1997 1998 1999 2000 2001 2002]\n",
      "[1994 1995 1996 1997 1998 1999 2000 2001 2002 2003]\n",
      "[1995 1996 1997 1998 1999 2000 2001 2002 2003 2004]\n",
      "[1996 1997 1998 1999 2000 2001 2002 2003 2004 2005]\n",
      "[1997 1998 1999 2000 2001 2002 2003 2004 2005 2006]\n",
      "[1998 1999 2000 2001 2002 2003 2004 2005 2006 2007]\n",
      "[1999 2000 2001 2002 2003 2004 2005 2006 2007 2008]\n",
      "[2000 2001 2002 2003 2004 2005 2006 2007 2008 2009]\n",
      "[2001 2002 2003 2004 2005 2006 2007 2008 2009 2010]\n",
      "[2002 2003 2004 2005 2006 2007 2008 2009 2010 2011]\n",
      "[2003 2004 2005 2006 2007 2008 2009 2010 2011 2012]\n",
      "[2004 2005 2006 2007 2008 2009 2010 2011 2012 2013]\n",
      "[2005 2006 2007 2008 2009 2010 2011 2012 2013 2014]\n",
      "[2006 2007 2008 2009 2010 2011 2012 2013 2014 2015]\n",
      "[2007 2008 2009 2010 2011 2012 2013 2014 2015 2016]\n",
      "[2008 2009 2010 2011 2012 2013 2014 2015 2016 2017]\n",
      "[2009 2010 2011 2012 2013 2014 2015 2016 2017 2018]\n",
      "[2010 2011 2012 2013 2014 2015 2016 2017 2018 2019]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'temp-plot.html'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import plot\n",
    "data = pd.read_csv('data/data.csv')\n",
    "\n",
    "year_grid = [x for x in range(1999,2020,1)]\n",
    "plot_data = []\n",
    "steps = []\n",
    "countries = data[['countrycode','country']].drop_duplicates().reset_index(drop=True)\n",
    "i=0\n",
    "for y in year_grid:\n",
    "    data_trimmed = data.loc[data.year <= y,:].loc[data.year > y-10, :]\n",
    "    print(data_trimmed.year.unique())\n",
    "    model = agglomerative_clustering(data_trimmed, 2, 'complete')\n",
    "    plot_data.append(dict(type='choropleth',\n",
    "        locations = countries['countrycode'].astype(str),\n",
    "        z=model.labels_))\n",
    "    # plot_data.append(dict(type='choroplethmapbox', marker_opacity=0.8,\n",
    "    #     locations = countries['countrycode'].astype(str), below=\"\",\n",
    "    #     z=['black']*len(year_grid)))\n",
    "    step = dict(method='restyle',\n",
    "                args=['visible', [False] * len(year_grid)],\n",
    "                label='{}'.format(y))\n",
    "    step['args'][1][i] = True\n",
    "    steps.append(step)\n",
    "    # step = dict(method='restyle',\n",
    "    #             args=['visible', [False] * len(year_grid)],\n",
    "    #             label='{}'.format(y))\n",
    "    # step['args'][1][i] = True\n",
    "    # steps.append(step)\n",
    "    i+=1\n",
    "\n",
    "sliders = [dict(active=0,\n",
    "                pad={\"t\": 1},\n",
    "                steps=steps)]\n",
    "                # dict(active=0,\n",
    "                # pad={\"t\": 1},\n",
    "                # steps=steps2)]    \n",
    "layout = dict(geo=dict(projection={'type': 'conic conformal'}, lataxis={'range':[35,75]}, \n",
    " lonaxis={'range' : [-15, 45]}),\n",
    "            sliders=sliders, showlegend=False)\n",
    "\n",
    "fig = dict(data=plot_data, \n",
    "        layout=layout)\n",
    "plot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\agama\\Documents\\BEngThesis\\django\\bengthesis\\lib\\site-packages\\pandas\\core\\indexing.py:1667: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cluster</th>\n",
       "      <th>pop</th>\n",
       "      <th>rgdpna_per_cap</th>\n",
       "      <th>net_migration</th>\n",
       "      <th>hdi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.017745</td>\n",
       "      <td>0.112512</td>\n",
       "      <td>0.205896</td>\n",
       "      <td>0.517123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cluster       pop  rgdpna_per_cap  net_migration       hdi\n",
       "0      2.0  0.017745        0.112512       0.205896  0.517123"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import plot\n",
    "data = pd.read_csv('data/data.csv')\n",
    "labels = [0,1,2]*13\n",
    "data_2019 = data[data.year == 2019]\n",
    "data_2019.loc[:, 'Cluster'] = pd.Series(labels)\n",
    "data_2019.groupby('Cluster').agg('mean')[['pop', 'rgdpna_per_cap', 'net_migration', 'hdi']].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0d1bfbd48ac9d0d45d3e1ecabc58d25c00d90cf1449842edf85d52c9d4642455"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('thesis': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
