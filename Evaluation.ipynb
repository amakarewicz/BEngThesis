{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*This notebook contains evaluation and comparison of algorithms used in the project, alongside with different distance calculation methods and transformation used. Further analysis consisting of multiple interactive and non-interactive plots can be found in 'Report_plots' notebook and 'Thesis_plots' notebook in 'plots' directory.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Imports & functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\agama\\Desktop\\thesis_env\\lib\\site-packages\\tslearn\\bases\\bases.py:15: UserWarning:\n",
      "\n",
      "h5py not installed, hdf5 features will not be supported.\n",
      "Install h5py to use hdf5 features: http://docs.h5py.org/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# required imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.offline import plot\n",
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "from dtaidistance import dtw_ndim\n",
    "from sklearn.cluster import AgglomerativeClustering, DBSCAN\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "import skfda\n",
    "\n",
    "# using R inside python\n",
    "import rpy2.robjects.packages as rpackages\n",
    "from rpy2.robjects.packages import importr\n",
    "import rpy2.robjects.numpy2ri\n",
    "import rpy2.robjects.pandas2ri\n",
    "\n",
    "rpy2.robjects.numpy2ri.activate()\n",
    "rpy2.robjects.pandas2ri.activate()\n",
    "\n",
    "# install R packages\n",
    "utils = rpackages.importr('utils')\n",
    "utils.chooseCRANmirror(ind=1)\n",
    "\n",
    "# run if not installed previously from requirements.txt\n",
    "# utils.install_packages('clValid')\n",
    "# utils.install_packages('symbolicDA')\n",
    "\n",
    "# load R packages\n",
    "clValid = importr('clValid')\n",
    "symbolicDA = importr('symbolicDA')\n",
    "stats = importr('stats')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (9, 6)\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_colwidth = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "def kmeans_clustering(data: pd.DataFrame, n_clusters: int, metric: str) -> TimeSeriesKMeans:\n",
    "    \"\"\"\n",
    "    Perform KMeans clustering.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): preprocessed dataframe with economic indexes\n",
    "        n_clusters (int): number of clusters to be formed\n",
    "\n",
    "    Returns:\n",
    "        TimeSeriesKMeans: fitted clustering model\n",
    "    \"\"\"\n",
    "    # transform input data into adequate structure - 3D numpy array\n",
    "    data_agg = data.drop('year', axis=1).groupby(['countrycode', 'country']).agg(list)\n",
    "    n_countries = data_agg.shape[0] # number of points (countries)\n",
    "    time_range =  len(data['year'].drop_duplicates()) # time range\n",
    "    n_vars = data.shape[1] - 3 # number of economic indexes\n",
    "    # filling the array\n",
    "    data_agg_arr = np.empty(shape=(n_countries, n_vars, time_range))\n",
    "    for i in range(data_agg.shape[0]):\n",
    "        for j in range(data_agg.shape[1]):\n",
    "            data_agg_arr[i][j] = np.array(data_agg.iloc[i,j])\n",
    "    # creating and fitting a model\n",
    "    model = TimeSeriesKMeans(n_clusters=n_clusters, metric=metric)\n",
    "    model.fit(data_agg_arr)\n",
    "    return model\n",
    "\n",
    "def agglomerative_clustering(matrix: np.matrix, n_clusters: int, linkage: str) -> AgglomerativeClustering:\n",
    "    \"\"\"\n",
    "    Perform hierarchical clustering.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): preprocessed dataframe with economic indexes\n",
    "        n_clusters (int): number of clusters to be formed\n",
    "        linkage (str): type of linkage criterion; 'average', 'complete' or 'single'\n",
    "\n",
    "    Returns:\n",
    "        AgglomerativeClustering: fitted clustering model\n",
    "    \"\"\"\n",
    "    # creating and fitting the model\n",
    "    model = AgglomerativeClustering(\n",
    "        n_clusters=n_clusters, affinity='precomputed', linkage=linkage, compute_distances=True)\n",
    "    model.fit(matrix)\n",
    "    return model\n",
    "\n",
    "def dbscan_clustering(matrix: np.matrix, eps: float, min_samples: int) -> DBSCAN:\n",
    "    \"\"\"\n",
    "    Perform DBSCAN clustering.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): preprocessed dataframe with economic indexes\n",
    "        eps (float): maximum distance between two points for them to be considered as neighbouring\n",
    "        min_samples (int): number of samples in a neighborhood for a point to be considered as a core point\n",
    "\n",
    "    Returns:\n",
    "        DBSCAN: fitted clustering model\n",
    "    \"\"\"\n",
    "    # creating and fitting the model\n",
    "    model = DBSCAN(eps=eps, min_samples=min_samples, metric='precomputed')\n",
    "    model.fit(matrix)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_dtw(data: pd.DataFrame) -> np.matrix:\n",
    "    \"\"\"\n",
    "    Calculate distances between countries according to Dynamic Time Warping method.\n",
    " \n",
    "    Args:\n",
    "        data (pd.DataFrame): preprocessed dataframe with economic indexes\n",
    "        \n",
    "    Returns:\n",
    "        np.matrix: square matrix containing distances between countries\n",
    "    \"\"\"\n",
    "    # creating distance matrix for searching for optimal parameters\n",
    "    # transform input data into adequate structure - 3D numpy array\n",
    "    data_t = data.melt(id_vars=['countrycode','country','year'])\n",
    "    data_t = data_t.groupby(['countrycode','country','year','variable'])['value'].aggregate('mean').unstack('year')\n",
    "    data_t = data_t.reset_index().drop('variable', axis=1).groupby(['countrycode', 'country']).agg(list)\n",
    "    n_countries = data_t.shape[0] # number of points (countries)\n",
    "    time_range =  data_t.shape[1] # time range\n",
    "    n_vars = data.shape[1] - 3 # number of economic indexes\n",
    "    # filling the array\n",
    "    data_t_arr = np.empty(shape=(n_countries, time_range, n_vars))\n",
    "    for i in range(n_countries):\n",
    "        for j in range(time_range):\n",
    "            data_t_arr[i][j] = np.array(data_t.iloc[i,j])\n",
    "    # calculating distances between points (countries)\n",
    "    dtw_matrix = dtw_ndim.distance_matrix_fast(data_t_arr, n_vars)\n",
    "    return dtw_matrix\n",
    "\n",
    "def calculate_euc(data: pd.DataFrame) -> np.matrix:\n",
    "    \"\"\"\n",
    "    Calculate distances between countries according to Euclidean distance measure.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): preprocessed dataframe with economic indexes\n",
    "        \n",
    "    Returns:\n",
    "        np.matrix: square matrix containing distances between countries\n",
    "    \"\"\"\n",
    "    # creating distance matrix for searching for optimal parameters\n",
    "    # transform input data into adequate structure - 3D numpy array\n",
    "    data_t = data.melt(id_vars=['countrycode','country','year'])\n",
    "    data_t = data_t.groupby(['countrycode','country','year', 'variable'])['value'].aggregate('mean').unstack('variable')\n",
    "    data_t = data_t.reset_index().drop('year', axis=1).groupby(['countrycode', 'country']).agg(list)\n",
    "    n_countries = data_t.shape[0] # number of points (countries)\n",
    "    n_vars =  data.shape[1] - 3 # number of economic indexes\n",
    "    time_range = len(data_t.iloc[0,0]) # time range\n",
    "    # filling the array\n",
    "    data_t_arr = np.empty(shape=(n_countries, n_vars, time_range))\n",
    "    for i in range(n_countries):\n",
    "        for j in range(n_vars):\n",
    "            data_t_arr[i][j] = np.array(data_t.iloc[i,j])\n",
    "    data_t_arr_flat = np.empty(shape=(n_countries, n_vars*time_range))\n",
    "    for i in range(data_t_arr.shape[0]):\n",
    "        data_t_arr_flat[i] = np.concatenate(data_t_arr[i])\n",
    "    # calculating distances between points (countries)\n",
    "    euc_matrix = euclidean_distances(data_t_arr_flat, data_t_arr_flat)\n",
    "    return euc_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading data (after different transformations)\n",
    "data = pd.read_csv('data/data.csv')\n",
    "data_box = pd.read_csv('data/data_box.csv')\n",
    "data_log = pd.read_csv('data/data_log.csv')\n",
    "data_out = pd.read_csv('data/data_out.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting list of pairs (country name + country code) for plots\n",
    "countries = data[['countrycode','country']].drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating distance matrix for data after different transformations\n",
    "euc_matrix = calculate_euc(data)\n",
    "dtw_matrix = calculate_dtw(data)\n",
    "euc_matrix_box = calculate_euc(data_box)\n",
    "dtw_matrix_box = calculate_dtw(data_box)\n",
    "euc_matrix_log = calculate_euc(data_log)\n",
    "dtw_matrix_log = calculate_dtw(data_log)\n",
    "euc_matrix_out = calculate_euc(data_out)\n",
    "dtw_matrix_out = calculate_dtw(data_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation of KMeans and Agglomerative clustering methods\n",
    "# comparison of different distance calculation methods and preprocessing pipelines\n",
    "matrices = [euc_matrix, euc_matrix_box, euc_matrix_log, euc_matrix_out, dtw_matrix, dtw_matrix_box, dtw_matrix_log, dtw_matrix_out]\n",
    "dataframes = [data, data_box, data_log, data_out]\n",
    "metrics = ['euclidean', 'dtw']\n",
    "\n",
    "k_max = 8\n",
    "silhouette = []\n",
    "chscore = []\n",
    "dunnindex = []\n",
    "# KMeans\n",
    "for m in metrics:\n",
    "    for d in dataframes:\n",
    "        for k in range(2, k_max+1):\n",
    "            kmeans = kmeans_clustering(d, k, m)\n",
    "            silhouette.append(silhouette_score(dtw_matrix, kmeans.labels_))\n",
    "            chscore.append(symbolicDA.index_G1d(dtw_matrix, kmeans.labels_+1)[0])\n",
    "            dunnindex.append(clValid.dunn(dtw_matrix, kmeans.labels_+1)[0])\n",
    "# Agglomerative (different linkages)\n",
    "for m in matrices:\n",
    "    for link in ['average', 'complete', 'single']: \n",
    "        for k in range(2, k_max+1):\n",
    "            agg = agglomerative_clustering(m, k, linkage=link)\n",
    "            silhouette.append(silhouette_score(m, agg.labels_))\n",
    "            chscore.append(symbolicDA.index_G1d(m, agg.labels_+1)[0])\n",
    "            dunnindex.append(clValid.dunn(m, agg.labels_+1)[0])\n",
    "# dataframe with all the results (Hierarchical = Agglomerative, code written before nomenclature was changed)           \n",
    "metrics = pd.DataFrame({'silhouette' : silhouette, 'chscore' : chscore, 'dunnindex' : dunnindex})\n",
    "metrics['data'] = pd.Series(['Euc']*7 + ['Euc_box']*7 + ['Euc_log']*7 + ['Euc_out']*7 + ['Dtw']*7 + ['Dtw_box']*7 + ['Dtw_log']*7 + ['Dtw_out']*7 + ['Euc']*21 + ['Euc_box']*21 + ['Euc_log']*21 + ['Euc_out']*21 + ['Dtw']*21 + ['Dtw_box']*21 + ['Dtw_log']*21 + ['Dtw_out']*21)\n",
    "metrics['algorithm'] = pd.concat([pd.Series(['KMeans']*56), pd.Series((['Hierarchical average']*7 + ['Hierarchical complete']*7 + ['Hierarchical single']*7)*8).reset_index(drop=True)], axis=0).reset_index(drop=True)\n",
    "metrics['n_clusters'] = pd.Series([x for x in range(2,9)]*4*8)\n",
    "metrics = metrics[['data', 'algorithm', 'n_clusters', 'silhouette', 'chscore', 'dunnindex']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a column with combination of distance method name, transformation name and algorithm name\n",
    "metrics['name'] = metrics['data'] + \" \" + metrics['algorithm']\n",
    "metrics = metrics.drop('data', axis=1)\n",
    "metrics['algorithm'] = metrics['name']\n",
    "metrics = metrics.drop('name', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithm</th>\n",
       "      <th>n_clusters</th>\n",
       "      <th>silhouette</th>\n",
       "      <th>chscore</th>\n",
       "      <th>dunnindex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>Dtw Hierarchical average</td>\n",
       "      <td>3</td>\n",
       "      <td>0.313889</td>\n",
       "      <td>6.571529</td>\n",
       "      <td>0.414722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>Dtw Hierarchical complete</td>\n",
       "      <td>4</td>\n",
       "      <td>0.310625</td>\n",
       "      <td>62.274435</td>\n",
       "      <td>0.379686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>Dtw Hierarchical single</td>\n",
       "      <td>2</td>\n",
       "      <td>0.379560</td>\n",
       "      <td>4.298158</td>\n",
       "      <td>0.511341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Dtw KMeans</td>\n",
       "      <td>6</td>\n",
       "      <td>0.256338</td>\n",
       "      <td>55.625135</td>\n",
       "      <td>0.421798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>Dtw_box Hierarchical average</td>\n",
       "      <td>2</td>\n",
       "      <td>0.523408</td>\n",
       "      <td>23.191869</td>\n",
       "      <td>0.196471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>Dtw_box Hierarchical complete</td>\n",
       "      <td>5</td>\n",
       "      <td>0.409175</td>\n",
       "      <td>98.027287</td>\n",
       "      <td>0.243128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>Dtw_box Hierarchical single</td>\n",
       "      <td>3</td>\n",
       "      <td>0.245828</td>\n",
       "      <td>14.825600</td>\n",
       "      <td>0.196471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Dtw_box KMeans</td>\n",
       "      <td>2</td>\n",
       "      <td>0.090977</td>\n",
       "      <td>48.268526</td>\n",
       "      <td>0.176115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>Dtw_log Hierarchical average</td>\n",
       "      <td>2</td>\n",
       "      <td>0.322313</td>\n",
       "      <td>3.837429</td>\n",
       "      <td>0.455987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>Dtw_log Hierarchical complete</td>\n",
       "      <td>4</td>\n",
       "      <td>0.313243</td>\n",
       "      <td>75.468281</td>\n",
       "      <td>0.386062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>Dtw_log Hierarchical single</td>\n",
       "      <td>2</td>\n",
       "      <td>0.322313</td>\n",
       "      <td>3.837429</td>\n",
       "      <td>0.455987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Dtw_log KMeans</td>\n",
       "      <td>2</td>\n",
       "      <td>0.288990</td>\n",
       "      <td>64.579902</td>\n",
       "      <td>0.237079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>Dtw_out Hierarchical average</td>\n",
       "      <td>3</td>\n",
       "      <td>0.310954</td>\n",
       "      <td>6.429977</td>\n",
       "      <td>0.423454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>Dtw_out Hierarchical complete</td>\n",
       "      <td>5</td>\n",
       "      <td>0.286078</td>\n",
       "      <td>64.053317</td>\n",
       "      <td>0.387476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>Dtw_out Hierarchical single</td>\n",
       "      <td>2</td>\n",
       "      <td>0.396606</td>\n",
       "      <td>4.384153</td>\n",
       "      <td>0.536743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Dtw_out KMeans</td>\n",
       "      <td>3</td>\n",
       "      <td>0.288969</td>\n",
       "      <td>52.839357</td>\n",
       "      <td>0.293818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Euc Hierarchical average</td>\n",
       "      <td>3</td>\n",
       "      <td>0.314123</td>\n",
       "      <td>6.570819</td>\n",
       "      <td>0.414722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Euc Hierarchical complete</td>\n",
       "      <td>4</td>\n",
       "      <td>0.308091</td>\n",
       "      <td>74.734342</td>\n",
       "      <td>0.363967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Euc Hierarchical single</td>\n",
       "      <td>2</td>\n",
       "      <td>0.379384</td>\n",
       "      <td>4.289905</td>\n",
       "      <td>0.511341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Euc KMeans</td>\n",
       "      <td>6</td>\n",
       "      <td>0.320023</td>\n",
       "      <td>42.724674</td>\n",
       "      <td>0.394044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Euc_box Hierarchical average</td>\n",
       "      <td>2</td>\n",
       "      <td>0.487539</td>\n",
       "      <td>20.214097</td>\n",
       "      <td>0.214006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Euc_box Hierarchical complete</td>\n",
       "      <td>7</td>\n",
       "      <td>0.416725</td>\n",
       "      <td>83.671652</td>\n",
       "      <td>0.305867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Euc_box Hierarchical single</td>\n",
       "      <td>4</td>\n",
       "      <td>0.202690</td>\n",
       "      <td>12.258566</td>\n",
       "      <td>0.243461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Euc_box KMeans</td>\n",
       "      <td>2</td>\n",
       "      <td>0.090977</td>\n",
       "      <td>48.268526</td>\n",
       "      <td>0.176115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Euc_log Hierarchical average</td>\n",
       "      <td>2</td>\n",
       "      <td>0.321784</td>\n",
       "      <td>3.825735</td>\n",
       "      <td>0.455987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>Euc_log Hierarchical complete</td>\n",
       "      <td>4</td>\n",
       "      <td>0.313602</td>\n",
       "      <td>75.482192</td>\n",
       "      <td>0.386062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>Euc_log Hierarchical single</td>\n",
       "      <td>2</td>\n",
       "      <td>0.321784</td>\n",
       "      <td>3.825735</td>\n",
       "      <td>0.455987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Euc_log KMeans</td>\n",
       "      <td>4</td>\n",
       "      <td>0.325335</td>\n",
       "      <td>62.529734</td>\n",
       "      <td>0.379686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>Euc_out Hierarchical average</td>\n",
       "      <td>3</td>\n",
       "      <td>0.311378</td>\n",
       "      <td>6.430352</td>\n",
       "      <td>0.423454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>Euc_out Hierarchical complete</td>\n",
       "      <td>5</td>\n",
       "      <td>0.286577</td>\n",
       "      <td>64.008659</td>\n",
       "      <td>0.387523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>Euc_out Hierarchical single</td>\n",
       "      <td>2</td>\n",
       "      <td>0.396050</td>\n",
       "      <td>4.369356</td>\n",
       "      <td>0.536743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Euc_out KMeans</td>\n",
       "      <td>4</td>\n",
       "      <td>0.293452</td>\n",
       "      <td>71.758590</td>\n",
       "      <td>0.377618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         algorithm  n_clusters  silhouette    chscore  \\\n",
       "141       Dtw Hierarchical average           3    0.313889   6.571529   \n",
       "149      Dtw Hierarchical complete           4    0.310625  62.274435   \n",
       "154        Dtw Hierarchical single           2    0.379560   4.298158   \n",
       "32                      Dtw KMeans           6    0.256338  55.625135   \n",
       "161   Dtw_box Hierarchical average           2    0.523408  23.191869   \n",
       "171  Dtw_box Hierarchical complete           5    0.409175  98.027287   \n",
       "176    Dtw_box Hierarchical single           3    0.245828  14.825600   \n",
       "35                  Dtw_box KMeans           2    0.090977  48.268526   \n",
       "182   Dtw_log Hierarchical average           2    0.322313   3.837429   \n",
       "191  Dtw_log Hierarchical complete           4    0.313243  75.468281   \n",
       "196    Dtw_log Hierarchical single           2    0.322313   3.837429   \n",
       "42                  Dtw_log KMeans           2    0.288990  64.579902   \n",
       "204   Dtw_out Hierarchical average           3    0.310954   6.429977   \n",
       "213  Dtw_out Hierarchical complete           5    0.286078  64.053317   \n",
       "217    Dtw_out Hierarchical single           2    0.396606   4.384153   \n",
       "50                  Dtw_out KMeans           3    0.288969  52.839357   \n",
       "57        Euc Hierarchical average           3    0.314123   6.570819   \n",
       "65       Euc Hierarchical complete           4    0.308091  74.734342   \n",
       "70         Euc Hierarchical single           2    0.379384   4.289905   \n",
       "4                       Euc KMeans           6    0.320023  42.724674   \n",
       "77    Euc_box Hierarchical average           2    0.487539  20.214097   \n",
       "89   Euc_box Hierarchical complete           7    0.416725  83.671652   \n",
       "93     Euc_box Hierarchical single           4    0.202690  12.258566   \n",
       "7                   Euc_box KMeans           2    0.090977  48.268526   \n",
       "98    Euc_log Hierarchical average           2    0.321784   3.825735   \n",
       "107  Euc_log Hierarchical complete           4    0.313602  75.482192   \n",
       "112    Euc_log Hierarchical single           2    0.321784   3.825735   \n",
       "16                  Euc_log KMeans           4    0.325335  62.529734   \n",
       "120   Euc_out Hierarchical average           3    0.311378   6.430352   \n",
       "129  Euc_out Hierarchical complete           5    0.286577  64.008659   \n",
       "133    Euc_out Hierarchical single           2    0.396050   4.369356   \n",
       "23                  Euc_out KMeans           4    0.293452  71.758590   \n",
       "\n",
       "     dunnindex  \n",
       "141   0.414722  \n",
       "149   0.379686  \n",
       "154   0.511341  \n",
       "32    0.421798  \n",
       "161   0.196471  \n",
       "171   0.243128  \n",
       "176   0.196471  \n",
       "35    0.176115  \n",
       "182   0.455987  \n",
       "191   0.386062  \n",
       "196   0.455987  \n",
       "42    0.237079  \n",
       "204   0.423454  \n",
       "213   0.387476  \n",
       "217   0.536743  \n",
       "50    0.293818  \n",
       "57    0.414722  \n",
       "65    0.363967  \n",
       "70    0.511341  \n",
       "4     0.394044  \n",
       "77    0.214006  \n",
       "89    0.305867  \n",
       "93    0.243461  \n",
       "7     0.176115  \n",
       "98    0.455987  \n",
       "107   0.386062  \n",
       "112   0.455987  \n",
       "16    0.379686  \n",
       "120   0.423454  \n",
       "129   0.387523  \n",
       "133   0.536743  \n",
       "23    0.377618  "
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# selecting best results for each combination of distance method, transformation and algorithm\n",
    "idx = metrics.groupby(['algorithm'])['silhouette'].transform(max) == metrics['silhouette']\n",
    "metrics[idx].sort_values('algorithm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'metrics.html'"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plotting the results \n",
    "# initializing figure\n",
    "fig = go.Figure()\n",
    "buttons = list()\n",
    "for i in range(metrics.shape[1]-2):\n",
    "    m = metrics.columns[i+2,]\n",
    "    df_test = metrics[['algorithm','n_clusters', m]]\n",
    "\n",
    "    # transposing data\n",
    "    df_test_transposed = df_test.pivot_table(index='algorithm', columns=['n_clusters'], values=m).reset_index()\n",
    "    df_test_final = df_test_transposed.rename_axis('').rename_axis(\"\", axis=\"columns\").set_index('algorithm')\n",
    "\n",
    "    # adding traces\n",
    "    for alg in df_test_final.index:\n",
    "        if i==0: # setting first layer to be visible on the load\n",
    "            fig.add_trace(go.Scatter(x=df_test_final.columns, y=df_test_final.loc[alg],\n",
    "                    name=alg, visible=True))            \n",
    "        else:\n",
    "            fig.add_trace(go.Scatter(x=df_test_final.columns, y=df_test_final.loc[alg],\n",
    "                    name=alg, visible=False))\n",
    "    n_of_countries = df_test_final.shape[0]\n",
    "    # setting visibility\n",
    "    visible = [False]*n_of_countries*i + [True]*n_of_countries + [False]*n_of_countries*(n_of_countries-i-1)\n",
    "    buttons.append(dict(label = m,\n",
    "                method = 'update',\n",
    "                args = [{'visible': visible},\n",
    "                        {'title': m}]))    \n",
    "fig.update_layout(dict(updatemenus=[dict(\n",
    "    type='dropdown', buttons=buttons, xanchor='right', x=1, y=1.15, active=0)],\n",
    "    title='Metrics'))\n",
    "# saving plot to HTML file\n",
    "plot(fig, filename='plots/metrics_2.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation of DBSCAN clustering method\n",
    "# comparison of different distance calculation methods and preprocessing pipelines\n",
    "matrices = [euc_matrix, euc_matrix_box, euc_matrix_log, euc_matrix_out, dtw_matrix, dtw_matrix_box, dtw_matrix_log, dtw_matrix_out]\n",
    "silhouette = []\n",
    "chscore = []\n",
    "dunnindex = []\n",
    "n_clusters = []\n",
    "params = []\n",
    "min_grid = [x for x in range(2, 11, 1)] # min_samples parameter\n",
    "eps_grid = np.arange(0.1, 10.1, 0.1) # eps parameter\n",
    "for matrix in matrices:\n",
    "    for m in min_grid:\n",
    "        for e in eps_grid:\n",
    "            dbscan = dbscan_clustering(eps = e, min_samples = m, matrix=matrix)\n",
    "            if len(set(dbscan.labels_)) < 3: # obtaining one cluster and outliers is not considered as a valid grouping\n",
    "                silhouette.append(-2) # adding value from outside metrics range to ignore those results during aggregation\n",
    "                chscore.append(-2)\n",
    "                dunnindex.append(-2)\n",
    "            else:\n",
    "                silhouette.append(silhouette_score(matrix, dbscan.labels_))\n",
    "                chscore.append(symbolicDA.index_G1d(matrix, dbscan.labels_+2)[0]) \n",
    "                dunnindex.append(clValid.dunn(matrix, dbscan.labels_+2)[0])\n",
    "            n_clusters.append(len(set(dbscan.labels_))-1)\n",
    "            params.append('[' + str(m) + ', ' + str(e) + ']')\n",
    "metrics2 = pd.DataFrame({'params' : params, 'n_clusters' : n_clusters, 'silhouette' : silhouette, 'chscore' : chscore, 'dunnindex' : dunnindex})\n",
    "metrics2['data'] = pd.Series(['Euc']*900 + ['Euc_box']*900 + ['Euc_log']*900 + ['Euc_out']*900 + ['Dtw']*900 + ['Dtw_box']*900 + ['Dtw_log']*900 + ['Dtw_out']*900)\n",
    "metrics2 = metrics2[['data', 'params', 'n_clusters', 'silhouette', 'chscore', 'dunnindex']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>n_clusters</th>\n",
       "      <th>silhouette</th>\n",
       "      <th>chscore</th>\n",
       "      <th>dunnindex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Euc</td>\n",
       "      <td>2</td>\n",
       "      <td>0.188728</td>\n",
       "      <td>37.439123</td>\n",
       "      <td>0.289175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>Euc_box</td>\n",
       "      <td>2</td>\n",
       "      <td>0.332514</td>\n",
       "      <td>23.861521</td>\n",
       "      <td>0.152342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025</th>\n",
       "      <td>Euc_log</td>\n",
       "      <td>2</td>\n",
       "      <td>0.214227</td>\n",
       "      <td>37.685930</td>\n",
       "      <td>0.288846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2733</th>\n",
       "      <td>Euc_out</td>\n",
       "      <td>2</td>\n",
       "      <td>0.179228</td>\n",
       "      <td>36.650473</td>\n",
       "      <td>0.294404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3631</th>\n",
       "      <td>Dtw</td>\n",
       "      <td>2</td>\n",
       "      <td>0.188416</td>\n",
       "      <td>37.454872</td>\n",
       "      <td>0.289175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4573</th>\n",
       "      <td>Dtw_box</td>\n",
       "      <td>2</td>\n",
       "      <td>0.377507</td>\n",
       "      <td>31.992544</td>\n",
       "      <td>0.112566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5625</th>\n",
       "      <td>Dtw_log</td>\n",
       "      <td>2</td>\n",
       "      <td>0.213558</td>\n",
       "      <td>37.686497</td>\n",
       "      <td>0.288846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6333</th>\n",
       "      <td>Dtw_out</td>\n",
       "      <td>2</td>\n",
       "      <td>0.179019</td>\n",
       "      <td>36.664640</td>\n",
       "      <td>0.294404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         data  n_clusters  silhouette    chscore  dunnindex\n",
       "31        Euc           2    0.188728  37.439123   0.289175\n",
       "994   Euc_box           2    0.332514  23.861521   0.152342\n",
       "2025  Euc_log           2    0.214227  37.685930   0.288846\n",
       "2733  Euc_out           2    0.179228  36.650473   0.294404\n",
       "3631      Dtw           2    0.188416  37.454872   0.289175\n",
       "4573  Dtw_box           2    0.377507  31.992544   0.112566\n",
       "5625  Dtw_log           2    0.213558  37.686497   0.288846\n",
       "6333  Dtw_out           2    0.179019  36.664640   0.294404"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# selecting best results for each combination of distance method and transformation\n",
    "idx2 = metrics2.groupby(['data'])['silhouette'].transform(max) == metrics2['silhouette']\n",
    "metrics2[idx2].drop(['params'], axis=1).drop_duplicates()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1ec50d26158d2b7350128d09b98f52f255d8aa2e11718915df200041349f2a51"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
