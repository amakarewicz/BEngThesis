{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*This notebook contains the code responsible for creating plots which are presented on the 'Report' page of the application.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Imports & functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# required imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objs as go \n",
    "from plotly.offline import plot\n",
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "from dtaidistance import dtw_ndim\n",
    "from sklearn.cluster import AgglomerativeClustering, DBSCAN\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# using R inside python\n",
    "import rpy2.robjects.packages as rpackages\n",
    "from rpy2.robjects.packages import importr\n",
    "import rpy2.robjects.numpy2ri\n",
    "import rpy2.robjects.pandas2ri\n",
    "\n",
    "rpy2.robjects.numpy2ri.activate()\n",
    "rpy2.robjects.pandas2ri.activate()\n",
    "\n",
    "# install R packages\n",
    "utils = rpackages.importr('utils')\n",
    "utils.chooseCRANmirror(ind=1)\n",
    "\n",
    "# run if not installed previously from requirements.txt\n",
    "# utils.install_packages('clValid')\n",
    "# utils.install_packages('symbolicDA')\n",
    "\n",
    "# load R packages\n",
    "clValid = importr('clValid')\n",
    "symbolicDA = importr('symbolicDA')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (9, 6)\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_colwidth = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "def kmeans_clustering(data: pd.DataFrame, n_clusters: int) -> TimeSeriesKMeans:\n",
    "    \"\"\"\n",
    "    Perform KMeans clustering.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): preprocessed dataframe with economic indexes\n",
    "        n_clusters (int): number of clusters to be formed\n",
    "\n",
    "    Returns:\n",
    "        TimeSeriesKMeans: fitted clustering model\n",
    "    \"\"\"\n",
    "    # transform input data into adequate structure - 3D numpy array\n",
    "    data_agg = data.drop('year', axis=1).groupby(['countrycode', 'country']).agg(list)\n",
    "    n_countries = data_agg.shape[0] # number of points (countries)\n",
    "    time_range =  len(data['year'].drop_duplicates()) # time range\n",
    "    n_vars = data.shape[1] - 3 # number of economic indexes\n",
    "    # filling the array\n",
    "    data_agg_arr = np.empty(shape=(n_countries, n_vars, time_range))\n",
    "    for i in range(data_agg.shape[0]):\n",
    "        for j in range(data_agg.shape[1]):\n",
    "            data_agg_arr[i][j] = np.array(data_agg.iloc[i,j])\n",
    "    # creating and fitting a model\n",
    "    model = TimeSeriesKMeans(n_clusters=n_clusters, metric='dtw')\n",
    "    model.fit(data_agg_arr)\n",
    "    return model\n",
    "\n",
    "def agglomerative_clustering(data: pd.DataFrame, n_clusters: int, linkage: str) -> AgglomerativeClustering:\n",
    "    \"\"\"\n",
    "    Perform hierarchical clustering.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): preprocessed dataframe with economic indexes\n",
    "        n_clusters (int): number of clusters to be formed\n",
    "        linkage (str): type of linkage criterion; 'average', 'complete' or 'single'\n",
    "\n",
    "    Returns:\n",
    "        AgglomerativeClustering: fitted clustering model\n",
    "    \"\"\"\n",
    "    # transform input data into adequate structure - 3D numpy array\n",
    "    data_t = data.melt(id_vars=['countrycode','country','year'])\n",
    "    data_t = data_t.groupby(['countrycode','country','year','variable'])['value'].aggregate('mean').unstack('year')\n",
    "    data_t = data_t.reset_index().drop('variable', axis=1).groupby(['countrycode', 'country']).agg(list)\n",
    "    n_countries = data_t.shape[0] # number of points (countries)\n",
    "    time_range =  data_t.shape[1] # time range\n",
    "    n_vars = data.shape[1] - 3 # number of economic indexes\n",
    "    # filling the array\n",
    "    data_t_arr = np.empty(shape=(n_countries, time_range, n_vars))\n",
    "    for i in range(n_countries):\n",
    "        for j in range(time_range):\n",
    "            data_t_arr[i][j] = np.array(data_t.iloc[i,j])\n",
    "    # calculating distances between points (countries)\n",
    "    dtw_matrix = dtw_ndim.distance_matrix_fast(data_t_arr, n_vars)\n",
    "    # creating and fitting the model\n",
    "    model = AgglomerativeClustering(\n",
    "        n_clusters=n_clusters, affinity='precomputed', linkage=linkage, compute_distances=True)\n",
    "    model.fit(dtw_matrix)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading data after standard preprocessing (normalization, imputation, smoothing)\n",
    "data = pd.read_csv('./../data/data.csv')\n",
    "# reading data after imputation (only)\n",
    "data_orig = pd.read_csv('./../data/data_imputed.csv')\n",
    "# reading data after box cox transformation\n",
    "data_box = pd.read_csv('./../data/data_box.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating distance matrix for searching for optimal parameters\n",
    "# transform input data into adequate structure - 3D numpy array\n",
    "data_t = data.melt(id_vars=['countrycode','country','year'])\n",
    "data_t = data_t.groupby(['countrycode','country','year','variable'])['value'].aggregate('mean').unstack('year')\n",
    "data_t = data_t.reset_index().drop('variable', axis=1).groupby(['countrycode', 'country']).agg(list)\n",
    "n_countries = data_t.shape[0] # number of points (countries)\n",
    "time_range =  data_t.shape[1] # time range\n",
    "n_vars = data.shape[1] - 3 # number of economic indexes\n",
    "# filling the array\n",
    "data_t_arr = np.empty(shape=(n_countries, time_range, n_vars))\n",
    "for i in range(n_countries):\n",
    "    for j in range(time_range):\n",
    "        data_t_arr[i][j] = np.array(data_t.iloc[i,j])\n",
    "# calculating distances between points (countries)\n",
    "dtw_matrix = dtw_ndim.distance_matrix_fast(data_t_arr, n_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Metrics (KMeans & Agglomerative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clustering algorithms comparison\n",
    "# arrays for metrics values\n",
    "# results already saved to csv - read in the next chunk\n",
    "k_max = 8\n",
    "silhouette = []\n",
    "chscore = []\n",
    "dunnindex = []\n",
    "for k in range(2, k_max+1): # KMeans\n",
    "    kmeans = kmeans_clustering(data, k)\n",
    "    silhouette.append(silhouette_score(dtw_matrix, kmeans.labels_))\n",
    "    chscore.append(symbolicDA.index_G1d(dtw_matrix, kmeans.labels_+1)[0])\n",
    "    dunnindex.append(clValid.dunn(dtw_matrix, kmeans.labels_+1)[0])\n",
    "for link in ['average', 'complete', 'single']: # Agglomerative (different linkages)\n",
    "    for k in range(2, k_max+1):\n",
    "        agg = agglomerative_clustering(data, k, linkage=link)\n",
    "        silhouette.append(silhouette_score(dtw_matrix, agg.labels_))\n",
    "        chscore.append(symbolicDA.index_G1d(dtw_matrix, agg.labels_+1)[0])\n",
    "        dunnindex.append(clValid.dunn(dtw_matrix, agg.labels_+1)[0])\n",
    "metrics = pd.DataFrame({'Silhouette' : silhouette, 'Calinski-Harabasz Index': chscore, 'Dunn Index': dunnindex})\n",
    "metrics['algorithm'] = pd.Series(['K-Means']*7 + ['Agglomerative average-linkage']*7 + ['Agglomerative complete-linkage']*7 + ['Agglomerative single-linkage']*7)\n",
    "metrics['n_clusters'] = pd.Series([x for x in range(2,9)]*4)\n",
    "metrics = metrics[['algorithm', 'n_clusters', 'silhouette', 'chscore', 'dunnindex']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving results\n",
    "# metrics.to_csv('./../data/metrics_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading results\n",
    "metrics=pd.read_csv('./../data/metrics_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'metrics.html'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initializing figure\n",
    "fig = go.Figure()\n",
    "buttons = list()\n",
    "for i in range(metrics.shape[1]-2):\n",
    "    m = metrics.columns[i+2,]\n",
    "    df_test = metrics[['algorithm','n_clusters', m]]\n",
    "\n",
    "    # transposing data\n",
    "    df_test_transposed = df_test.pivot_table(index='algorithm', columns=['n_clusters'], values=m).reset_index()\n",
    "    df_test_final = df_test_transposed.rename_axis('').rename_axis(\"\", axis=\"columns\").set_index('algorithm')\n",
    "\n",
    "    # adding traces\n",
    "    for alg in df_test_final.index:\n",
    "        if i==0: # setting first layer to be visible on the load\n",
    "            fig.add_trace(go.Scatter(x=df_test_final.columns, y=df_test_final.loc[alg],\n",
    "                    name=alg, visible=True))            \n",
    "        else:\n",
    "            fig.add_trace(go.Scatter(x=df_test_final.columns, y=df_test_final.loc[alg],\n",
    "                    name=alg, visible=False))\n",
    "    n_of_countries = df_test_final.shape[0]\n",
    "    # setting visibility\n",
    "    visible = [False]*n_of_countries*i + [True]*n_of_countries + [False]*n_of_countries*(n_of_countries-i-1)\n",
    "    buttons.append(dict(label = m,\n",
    "                method = 'update',\n",
    "                args = [{'visible': visible},\n",
    "                        {'title': m}]))    \n",
    "fig.update_layout(dict(updatemenus=[dict(\n",
    "    type='dropdown', buttons=buttons, xanchor='right', x=1, y=1.15, active=0)],\n",
    "    title='Metrics', xaxis_title=\"Number of clusters\",\n",
    "    yaxis_title=\"Metric value\",\n",
    "    legend_title=\"Algorithm\", legend_font_size=16,\n",
    "    legend_title_font_size=18))\n",
    "fig.update_xaxes(tickfont_size= 16, title_font_size=18)\n",
    "fig.update_yaxes(tickfont_size= 16, title_font_size=18)\n",
    "# saving plot to HTML file\n",
    "plot(fig, filename='metrics.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dbscan.html'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countries = data[['countrycode', 'country']].drop_duplicates().reset_index(drop=True)\n",
    "# creating a plot with groupings created by DBSCAN algorithm with different parameters\n",
    "eps_grid = [3, 3.1, 3.2, 3.3, 3.4, 3.5]\n",
    "min_samples_grid = [3, 4, 5, 6, 7]\n",
    "plot_data = []\n",
    "for eps in eps_grid:\n",
    "    for min_samples in min_samples_grid:\n",
    "        model = DBSCAN(eps=eps, min_samples=min_samples, metric='precomputed')\n",
    "        model.fit(dtw_matrix)\n",
    "        labels = model.labels_.astype(str)\n",
    "        countries[\"cluster\"] = pd.Series(labels)\n",
    "        countries['cluster'] = np.where(countries['cluster'] == '-1', 'outlier', countries['cluster'])\n",
    "        # adding layers with different groupings\n",
    "        plot_data.append(dict(type='choropleth',\n",
    "                                locations=countries['countrycode'].astype(str),\n",
    "                                z=model.labels_.astype(str),\n",
    "                                colorscale=[[0, '#718355'], [0.33, '#ffe8d6'], [0.6, '#ddbea9'], [1, '#cb997e']],\n",
    "                                showscale=False,\n",
    "                                text = countries.apply(\n",
    "                                    lambda row: f\"<b>{row['country']}</b><br>ISO code: \\\n",
    "                                    {row['countrycode']}<br>Cluster: {row['cluster']} \",axis=1),\n",
    "                                hoverinfo = \"text\"))\n",
    "# setting visibility of layers\n",
    "steps = []\n",
    "i = 0\n",
    "for eps in eps_grid:\n",
    "    for min_samples in min_samples_grid:\n",
    "        step = dict(method='restyle',\n",
    "                    args=['visible', [False] * len(plot_data)],\n",
    "                    label='[{}, {}]'.format(eps, min_samples))\n",
    "        step['args'][1][i] = True\n",
    "        steps.append(step)\n",
    "        i += 1\n",
    "# adding slider with parameters values\n",
    "sliders = [dict(active=0,\n",
    "                steps=steps,\n",
    "                currentvalue={'prefix': 'Eps, min_samples - '},\n",
    "                len=0.9,\n",
    "                xanchor='center',\n",
    "                pad={\"l\":20,\"r\":20, \"t\":1},\n",
    "                ticklen=8,\n",
    "                x=0.5)]\n",
    "# customizing figure layout\n",
    "layout = dict(geo=dict(projection={'type': 'conic conformal'}, lataxis={'range': [35, 75]},\n",
    "                        lonaxis={'range': [-15, 45]}), sliders=sliders, title='DBSCAN')\n",
    "fig = go.Figure(dict(data=plot_data, layout=layout))\n",
    "fig.update_traces(showlegend=False, selector=dict(type='choropleth'))\n",
    "fig.update_layout(showlegend=False, margin=dict(l=10, r=10, t=50, b=20), paper_bgcolor='rgba(0,0,0,0)',\n",
    "                    hoverlabel=dict(bgcolor=\"white\", font_size=14), title_x=0.5, title_xref='paper')\n",
    "# saving plot to HTML file\n",
    "plot(fig, filename='dbscan.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V. Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'plots/series.html'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plotting figure presenting all economic indicators for all countries\n",
    "fig = go.Figure()\n",
    "buttons = list()\n",
    "for i in range(data_orig.shape[1] - 3):\n",
    "    ind = data_orig.columns[i + 3,]\n",
    "    df_test = data_orig[['countrycode', 'year', ind]]\n",
    "    # transposing data\n",
    "    df_test_transposed = df_test.pivot_table(index='countrycode', columns=['year'], values=ind).reset_index()\n",
    "    df_test_final = df_test_transposed.rename_axis('').rename_axis(\"\", axis=\"columns\"\n",
    "                                                                    ).set_index('countrycode')\n",
    "    # adding traces\n",
    "    countries = data[['countrycode', 'country']].drop_duplicates().reset_index(drop=True).set_index('countrycode')\n",
    "    for countrycode in df_test_final.index:\n",
    "        if i == 0: # setting first layer to be visible\n",
    "            fig.add_trace(go.Scatter(x=df_test_final.columns, y=df_test_final.loc[countrycode],\n",
    "                                        name=countrycode, visible=True,\n",
    "                                        text=[countries.loc[countrycode, 'country']] * 30,\n",
    "                                        hovertemplate=\n",
    "                                        \"Country: %{text}<br>\" +\n",
    "                                        \"Year: %{x}<br>\" +\n",
    "                                        \"Value: %{y}\" +\n",
    "                                        \"<extra></extra>\", \n",
    "                                        ))\n",
    "        else: # adding rest of the layers\n",
    "            fig.add_trace(go.Scatter(x=df_test_final.columns, y=df_test_final.loc[countrycode],\n",
    "                                        name=countrycode, visible=False,\n",
    "                                        text=[countries.loc[countrycode, 'country']] * 30,\n",
    "                                        hovertemplate=\n",
    "                                        \"Country: %{text}<br>\" +\n",
    "                                        \"Year: %{x}<br>\" +\n",
    "                                        \"Value: %{y}\" +\n",
    "                                        \"<extra></extra>\", \n",
    "                                        ))\n",
    "    n_of_countries = df_test_final.shape[0]\n",
    "    visible = [False] * n_of_countries * i + [True] * n_of_countries + [False] * n_of_countries * (\n",
    "            n_of_countries - i - 1)\n",
    "    buttons.append(dict(label=ind, method='update', args=[{'visible': visible}, {'title': ind}]))\n",
    "# customizing map layout\n",
    "updatemenus = list([dict(active=0, buttons=buttons, xanchor='right', x=1, y=1.15)])\n",
    "fig.update_layout(updatemenus=updatemenus, title='Series',\n",
    "                    title_x=0, title_xref='paper', margin=dict(l=20, r=20, t=20, b=20))\n",
    "# saving plot to HTML file\n",
    "plot(fig, filename='series.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VI. Segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'segments.html'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# analyzing changes in grouping through the years based on 10-year long segments, taken each 3 years\n",
    "year_grid = [x for x in range(1995, 2020, 3)]\n",
    "plot_data = []\n",
    "steps = []\n",
    "countries = data_box[['countrycode', 'country']].drop_duplicates().reset_index(drop=True)\n",
    "i = 0\n",
    "for y in year_grid:\n",
    "    data_trimmed = data_box.loc[data_box.year <= y, :].loc[data_box.year > y - 10, :]\n",
    "    model = agglomerative_clustering(data_trimmed, 4, 'complete')\n",
    "    # changing countries order to preserve the same colors for a given cluster for each grouping for better visualisation\n",
    "    order = [11, 30, 2, 3, 4, 5, 6, 7, 8, 9, 10, 0, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27,\n",
    "                28, 29, 1, 31, 32, 33, 34, 35, 36, 37, 38]\n",
    "    dictionary = {k: None for k in np.unique(model.labels_)}\n",
    "    label = 0\n",
    "    for j in order:\n",
    "        if dictionary[model.labels_[j]] is None:\n",
    "            dictionary[model.labels_[j]] = label\n",
    "            label += 1\n",
    "        model.labels_[j] = dictionary[model.labels_[j]]\n",
    "    labels = model.labels_.astype(str)\n",
    "    countries[\"cluster\"] = pd.Series(labels)\n",
    "    # adding layers with groupings\n",
    "    plot_data.append(dict(type='choropleth',\n",
    "                            locations=countries['countrycode'].astype(str),\n",
    "                            customdata=[\"country\", 'countrycode', 'cluster'],\n",
    "                            text=countries.apply(lambda row: f\"<b>{row['country']}</b><br>ISO code: {row['countrycode']}<br>Cluster: {row['cluster']} \", axis=1),\n",
    "                            hoverinfo=\"text\",\n",
    "                            z=model.labels_,  showscale = False, # colorscale = ['#f1faee', '#a8dadc', '#457b9d']))\n",
    "                            colorscale=[[0, '#f1faee'], [0.33, '#a8dadc'], [0.66, '#457b9d'], [1, '#1d3557']]))\n",
    "    # setting visibility\n",
    "    step = dict(method='restyle',\n",
    "                args=['visible', [False] * len(year_grid)],\n",
    "                label='{}'.format(y))\n",
    "    step['args'][1][i] = True\n",
    "    steps.append(step)\n",
    "    i += 1\n",
    "# adding slider with time range\n",
    "sliders = [dict(active=0,\n",
    "                pad={\"t\": 1},\n",
    "                steps=steps)]\n",
    "# customizing map layout\n",
    "layout = dict(geo=dict(projection={'type': 'conic conformal'}, lataxis={'range': [35, 75]},\n",
    "                        lonaxis={'range': [-15, 45]}),\n",
    "                sliders=sliders, showlegend=False)\n",
    "\n",
    "fig = go.Figure(dict(data=plot_data,layout=layout))\n",
    "fig.update_layout(title='Business cycles synchronization', showlegend=False, margin=dict(l=10, r=10, t=50, b=20), paper_bgcolor='rgba(0,0,0,0)',\n",
    "                    hoverlabel=dict(bgcolor=\"white\", font_size=14), title_x=0.5, title_xref='paper')\n",
    "# saving plot to HTML file\n",
    "plot(fig, filename='segments.html')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0d1bfbd48ac9d0d45d3e1ecabc58d25c00d90cf1449842edf85d52c9d4642455"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('thesis': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
